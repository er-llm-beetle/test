
# FOR API AND LOCAL VERSIONS

metadata:
  version: "1.0"
  author: "ER"
  description: "This notebook evaluates different LLM models across various benchmark types such as MMLU, FinanceQA, and Contextual QA."
  supported_models:
    # local: 
      # - llama3.1_az_8q
      # - llama3.1_az
      # - llama3.1_az_v2
      # - "llama3.2:3b-instruct-fp16"  
    api: 
      - gpt-4o-mini # uncomment if you want to use api based models
      - "ft:gpt-4o-mini-2024-07-18:kapital-bank:instruct-v1-az-1k-banking:AG3twG3Y"
      - "ft:gpt-4o-mini-2024-07-18:kapital-bank:instruct-v1-az-4k-banking:AGMjcNG7"
  benchmark_types:
    QA: "Handles questions with simple Q&A format"
    ContextQA: "Handles questions with context and answers"
    Arzuman: "Handles questions with options where one is correct"
    Reshad: "Handles questions with topic-based options where one is correct"
    ARC: "Handles questions with multiple-choice answers, focusing on reasoning and context to determine the correct option."

    kMC_azerbaycan_dili: "Handles questions with options where one is correct"
    kMC_azerbaycan_tarixi: "Handles questions with options where one is correct"
    kMC_biologiya: "Handles questions with options where one is correct"
    kMC_cografiya: "Handles questions with options where one is correct"
    kMC_edebiyyat: "Handles questions with options where one is correct"
    kMC_fizika: "Handles questions with options where one is correct"
    kMC_informatika: "Handles questions with options where one is correct"
    kMC_kimya: "Handles questions with options where one is correct"
    kMC_mentiq: "Handles questions with options where one is correct"
    kMC_tarix: "Handles questions with options where one is correct"

    QMC: "" # quadContextMC

    mMC: "" # mathMC

  dataset_naming_convention:
    _qa: "QA"
    _cqa: "ContextQA"
    _mmlu_fqa: "Arzuman"
    _tc: "Reshad"
    _mmlu_arc: "ARC"
    _kmc: "kMC"
    _qmc: "QMC"
    _mmc: "mMC"

  selection:
    mode:
      # - local
      - api # uncomment if you want to use api based models
dataset_files:
  - "datasets/input_datasets/LLM_generated_latest_qa.xlsx"
  - "datasets/input_datasets/Quad_benchmark_latest_cqa.xlsx"
  - "datasets/input_datasets/Banking-finance_benchmark_de-duplicated_latest_mmlu_fqa.xlsx"
  # # - "datasets/input_datasets/Banking_support_en-reshad_tc.xlsx"     # Reshad's old version with eng topic names
  - "datasets/input_datasets/Banking_support_aze_version_reshad_tc.xlsx"    # Reshad's updated aze. topic names
  # # - "datasets/input_datasets/arc_translated_mmlu_arc.xlsx"    # old ARC version
  - "datasets/input_datasets/arc_translated_cutted_with_extra_cols_and_options_structure_last_version_mmlu_arc.xlsx"  # new ARC eng version

  - "datasets/input_datasets/mmlu_aze-testler_azerbaycan_dili_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_azerbaycan_tarixi_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_biologiya_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_cografiya_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_edebiyyat_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_fizika_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_informatika_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_kimya_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_mentiq_kmc.xlsx"
  - "datasets/input_datasets/mmlu_aze-testler_tarix_kmc.xlsx"

  - "datasets/input_datasets/anl_quad_reshad_qmc.xlsx"

  - "datasets/input_datasets/gsm8k_mmc.xlsx"

output:
  results_file: "datasets/output_datasets/benchmark_results.xlsx"


















# ---------------------------------------




# # FOR API AND HF VERSIONS 

# metadata:
#   version: "1.0"
#   author: "ER"
#   description: "This notebook evaluates different LLM models across various benchmark types such as MMLU, FinanceQA, and Contextual QA."
#   supported_models:
#     hf: 
#       - name: "unsloth_llama3.1_8B_lora_v2"
#         model_file: "unsloth.Q4_K_M.gguf"
#       # - llama3.1_az
#       # - llama3.1_az_v2
#       # - "llama3.2:3b-instruct-fp16"  
#     # api: 
#       # - gpt-4o-mini # uncomment if you want to use api based models
#   benchmark_types:
#     # QA: "Handles questions with simple Q&A format"
#     # ContextQA: "Handles questions with context and answers"
#     # Arzuman: "Handles questions with options where one is correct"
#     # Reshad: "Handles questions with topic-based options where one is correct"
#     ARC: "Handles questions with multiple-choice answers, focusing on reasoning and context to determine the correct option."
#   dataset_naming_convention:
#     # _qa: "QA"
#     # _cqa: "ContextQA"
#     # _mmlu_fqa: "Arzuman"
#     # _tc: "Reshad"
#     _mmlu_arc: "ARC"
#   selection:
#     mode:
#       - local
#       # - api # uncomment if you want to use api based models
# dataset_files:
#   # - "datasets/input_datasets/LLM_generated_qa.xlsx"
#   # - "datasets/input_datasets/Quad_benchmark_cqa.xlsx"
#   # - "datasets/input_datasets/Banking-finance_benchmark_de-duplicated_latest_mmlu_fqa.xlsx"
#   # - "datasets/input_datasets/Banking_support_en-reshad_tc.xlsx"     # Reshad's old version with eng topic names
#   # - "datasets/input_datasets/Banking_support_aze_version_reshad_tc.xlsx"    # Reshad's updated aze. topic names
#   # - "datasets/input_datasets/arc_translated_mmlu_arc.xlsx"    # old ARC version
#   - "datasets/input_datasets/arc_translated_cutted_with_extra_cols_and_options_structure_last_version_mmlu_arc.xlsx"  # new ARC eng version
# output:
#   results_file: "datasets/output_datasets/benchmark_results.xlsx"





